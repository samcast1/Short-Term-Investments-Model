{
  "best_metric": 0.03358028084039688,
  "best_model_checkpoint": "./results/checkpoint-17484",
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 17484,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.008579272477693892,
      "grad_norm": 3.9993741512298584,
      "learning_rate": 1.7789327737112462e-06,
      "loss": 1.0567,
      "step": 50
    },
    {
      "epoch": 0.017158544955387784,
      "grad_norm": 5.156711101531982,
      "learning_rate": 3.5578655474224923e-06,
      "loss": 0.9967,
      "step": 100
    },
    {
      "epoch": 0.025737817433081674,
      "grad_norm": 2.7825822830200195,
      "learning_rate": 5.3367983211337385e-06,
      "loss": 0.9523,
      "step": 150
    },
    {
      "epoch": 0.03431708991077557,
      "grad_norm": 2.494576930999756,
      "learning_rate": 7.115731094844985e-06,
      "loss": 0.8156,
      "step": 200
    },
    {
      "epoch": 0.04289636238846946,
      "grad_norm": 4.911856651306152,
      "learning_rate": 8.89466386855623e-06,
      "loss": 0.7169,
      "step": 250
    },
    {
      "epoch": 0.05147563486616335,
      "grad_norm": 5.3241496086120605,
      "learning_rate": 1.0673596642267477e-05,
      "loss": 0.6038,
      "step": 300
    },
    {
      "epoch": 0.06005490734385724,
      "grad_norm": 4.646881580352783,
      "learning_rate": 1.2452529415978723e-05,
      "loss": 0.5626,
      "step": 350
    },
    {
      "epoch": 0.06863417982155114,
      "grad_norm": 7.002514362335205,
      "learning_rate": 1.423146218968997e-05,
      "loss": 0.5304,
      "step": 400
    },
    {
      "epoch": 0.07721345229924502,
      "grad_norm": 4.578517436981201,
      "learning_rate": 1.6010394963401215e-05,
      "loss": 0.5064,
      "step": 450
    },
    {
      "epoch": 0.08579272477693892,
      "grad_norm": 5.576064586639404,
      "learning_rate": 1.778932773711246e-05,
      "loss": 0.4679,
      "step": 500
    },
    {
      "epoch": 0.09437199725463281,
      "grad_norm": 4.628036975860596,
      "learning_rate": 1.9568260510823708e-05,
      "loss": 0.437,
      "step": 550
    },
    {
      "epoch": 0.1029512697323267,
      "grad_norm": 6.720689296722412,
      "learning_rate": 2.1347193284534954e-05,
      "loss": 0.418,
      "step": 600
    },
    {
      "epoch": 0.1115305422100206,
      "grad_norm": 5.2275800704956055,
      "learning_rate": 2.31261260582462e-05,
      "loss": 0.3992,
      "step": 650
    },
    {
      "epoch": 0.12010981468771448,
      "grad_norm": 11.091248512268066,
      "learning_rate": 2.4905058831957446e-05,
      "loss": 0.405,
      "step": 700
    },
    {
      "epoch": 0.12868908716540836,
      "grad_norm": 2.9633126258850098,
      "learning_rate": 2.6683991605668692e-05,
      "loss": 0.3638,
      "step": 750
    },
    {
      "epoch": 0.13726835964310227,
      "grad_norm": 6.233695030212402,
      "learning_rate": 2.846292437937994e-05,
      "loss": 0.3458,
      "step": 800
    },
    {
      "epoch": 0.14584763212079616,
      "grad_norm": 19.109384536743164,
      "learning_rate": 2.837762431830532e-05,
      "loss": 0.339,
      "step": 850
    },
    {
      "epoch": 0.15442690459849004,
      "grad_norm": 2.445995569229126,
      "learning_rate": 2.829232425723069e-05,
      "loss": 0.3753,
      "step": 900
    },
    {
      "epoch": 0.16300617707618395,
      "grad_norm": 5.957876682281494,
      "learning_rate": 2.820702419615607e-05,
      "loss": 0.2787,
      "step": 950
    },
    {
      "epoch": 0.17158544955387783,
      "grad_norm": 5.234116077423096,
      "learning_rate": 2.812172413508145e-05,
      "loss": 0.2632,
      "step": 1000
    },
    {
      "epoch": 0.18016472203157172,
      "grad_norm": 4.201688766479492,
      "learning_rate": 2.8036424074006828e-05,
      "loss": 0.2699,
      "step": 1050
    },
    {
      "epoch": 0.18874399450926563,
      "grad_norm": 3.444188117980957,
      "learning_rate": 2.7951124012932204e-05,
      "loss": 0.2648,
      "step": 1100
    },
    {
      "epoch": 0.1973232669869595,
      "grad_norm": 2.2784628868103027,
      "learning_rate": 2.7865823951857584e-05,
      "loss": 0.2684,
      "step": 1150
    },
    {
      "epoch": 0.2059025394646534,
      "grad_norm": 3.595349073410034,
      "learning_rate": 2.778052389078296e-05,
      "loss": 0.2245,
      "step": 1200
    },
    {
      "epoch": 0.21448181194234728,
      "grad_norm": 7.801037311553955,
      "learning_rate": 2.7695223829708337e-05,
      "loss": 0.2462,
      "step": 1250
    },
    {
      "epoch": 0.2230610844200412,
      "grad_norm": 5.768960952758789,
      "learning_rate": 2.7609923768633717e-05,
      "loss": 0.2313,
      "step": 1300
    },
    {
      "epoch": 0.23164035689773507,
      "grad_norm": 9.992330551147461,
      "learning_rate": 2.7524623707559093e-05,
      "loss": 0.2692,
      "step": 1350
    },
    {
      "epoch": 0.24021962937542896,
      "grad_norm": 2.6235146522521973,
      "learning_rate": 2.7439323646484473e-05,
      "loss": 0.2284,
      "step": 1400
    },
    {
      "epoch": 0.24879890185312287,
      "grad_norm": 7.876410961151123,
      "learning_rate": 2.735402358540985e-05,
      "loss": 0.226,
      "step": 1450
    },
    {
      "epoch": 0.2573781743308167,
      "grad_norm": 6.923704624176025,
      "learning_rate": 2.726872352433523e-05,
      "loss": 0.2127,
      "step": 1500
    },
    {
      "epoch": 0.26595744680851063,
      "grad_norm": 5.374861240386963,
      "learning_rate": 2.7183423463260606e-05,
      "loss": 0.1981,
      "step": 1550
    },
    {
      "epoch": 0.27453671928620454,
      "grad_norm": 2.967008113861084,
      "learning_rate": 2.7098123402185982e-05,
      "loss": 0.2175,
      "step": 1600
    },
    {
      "epoch": 0.2831159917638984,
      "grad_norm": 4.140583515167236,
      "learning_rate": 2.7012823341111362e-05,
      "loss": 0.1902,
      "step": 1650
    },
    {
      "epoch": 0.2916952642415923,
      "grad_norm": 3.2146236896514893,
      "learning_rate": 2.6927523280036738e-05,
      "loss": 0.189,
      "step": 1700
    },
    {
      "epoch": 0.3002745367192862,
      "grad_norm": 7.0558295249938965,
      "learning_rate": 2.6842223218962118e-05,
      "loss": 0.1718,
      "step": 1750
    },
    {
      "epoch": 0.3088538091969801,
      "grad_norm": 12.783110618591309,
      "learning_rate": 2.6756923157887494e-05,
      "loss": 0.1591,
      "step": 1800
    },
    {
      "epoch": 0.317433081674674,
      "grad_norm": 5.418948173522949,
      "learning_rate": 2.667162309681287e-05,
      "loss": 0.1688,
      "step": 1850
    },
    {
      "epoch": 0.3260123541523679,
      "grad_norm": 2.220125198364258,
      "learning_rate": 2.658632303573825e-05,
      "loss": 0.1682,
      "step": 1900
    },
    {
      "epoch": 0.33459162663006176,
      "grad_norm": 2.5137240886688232,
      "learning_rate": 2.650102297466363e-05,
      "loss": 0.1562,
      "step": 1950
    },
    {
      "epoch": 0.34317089910775567,
      "grad_norm": 9.776213645935059,
      "learning_rate": 2.6415722913589004e-05,
      "loss": 0.1511,
      "step": 2000
    },
    {
      "epoch": 0.3517501715854496,
      "grad_norm": 9.734404563903809,
      "learning_rate": 2.6330422852514383e-05,
      "loss": 0.162,
      "step": 2050
    },
    {
      "epoch": 0.36032944406314343,
      "grad_norm": 2.7612650394439697,
      "learning_rate": 2.6245122791439763e-05,
      "loss": 0.1585,
      "step": 2100
    },
    {
      "epoch": 0.36890871654083734,
      "grad_norm": 10.759623527526855,
      "learning_rate": 2.6159822730365136e-05,
      "loss": 0.158,
      "step": 2150
    },
    {
      "epoch": 0.37748798901853126,
      "grad_norm": 5.840686798095703,
      "learning_rate": 2.6074522669290516e-05,
      "loss": 0.1552,
      "step": 2200
    },
    {
      "epoch": 0.3860672614962251,
      "grad_norm": 1.5321227312088013,
      "learning_rate": 2.5989222608215896e-05,
      "loss": 0.1702,
      "step": 2250
    },
    {
      "epoch": 0.394646533973919,
      "grad_norm": 7.07520055770874,
      "learning_rate": 2.5903922547141272e-05,
      "loss": 0.1379,
      "step": 2300
    },
    {
      "epoch": 0.4032258064516129,
      "grad_norm": 2.469799757003784,
      "learning_rate": 2.581862248606665e-05,
      "loss": 0.141,
      "step": 2350
    },
    {
      "epoch": 0.4118050789293068,
      "grad_norm": 5.684584140777588,
      "learning_rate": 2.573332242499203e-05,
      "loss": 0.1331,
      "step": 2400
    },
    {
      "epoch": 0.4203843514070007,
      "grad_norm": 8.042335510253906,
      "learning_rate": 2.5648022363917405e-05,
      "loss": 0.1355,
      "step": 2450
    },
    {
      "epoch": 0.42896362388469456,
      "grad_norm": 4.364030361175537,
      "learning_rate": 2.556272230284278e-05,
      "loss": 0.1488,
      "step": 2500
    },
    {
      "epoch": 0.43754289636238847,
      "grad_norm": 4.317183971405029,
      "learning_rate": 2.547742224176816e-05,
      "loss": 0.1503,
      "step": 2550
    },
    {
      "epoch": 0.4461221688400824,
      "grad_norm": 3.101740598678589,
      "learning_rate": 2.539212218069354e-05,
      "loss": 0.1589,
      "step": 2600
    },
    {
      "epoch": 0.45470144131777623,
      "grad_norm": 8.68861198425293,
      "learning_rate": 2.5306822119618918e-05,
      "loss": 0.16,
      "step": 2650
    },
    {
      "epoch": 0.46328071379547014,
      "grad_norm": 2.5219409465789795,
      "learning_rate": 2.5221522058544294e-05,
      "loss": 0.1418,
      "step": 2700
    },
    {
      "epoch": 0.47185998627316406,
      "grad_norm": 10.268643379211426,
      "learning_rate": 2.5136221997469674e-05,
      "loss": 0.1383,
      "step": 2750
    },
    {
      "epoch": 0.4804392587508579,
      "grad_norm": 1.6728185415267944,
      "learning_rate": 2.505092193639505e-05,
      "loss": 0.1363,
      "step": 2800
    },
    {
      "epoch": 0.4890185312285518,
      "grad_norm": 3.079500913619995,
      "learning_rate": 2.4965621875320427e-05,
      "loss": 0.1327,
      "step": 2850
    },
    {
      "epoch": 0.49759780370624573,
      "grad_norm": 2.6057565212249756,
      "learning_rate": 2.4880321814245807e-05,
      "loss": 0.1212,
      "step": 2900
    },
    {
      "epoch": 0.5061770761839396,
      "grad_norm": 6.496104717254639,
      "learning_rate": 2.4795021753171183e-05,
      "loss": 0.124,
      "step": 2950
    },
    {
      "epoch": 0.5147563486616334,
      "grad_norm": 1.4534109830856323,
      "learning_rate": 2.4709721692096563e-05,
      "loss": 0.1166,
      "step": 3000
    },
    {
      "epoch": 0.5233356211393274,
      "grad_norm": 4.147218227386475,
      "learning_rate": 2.462442163102194e-05,
      "loss": 0.1198,
      "step": 3050
    },
    {
      "epoch": 0.5319148936170213,
      "grad_norm": 11.18271541595459,
      "learning_rate": 2.4539121569947316e-05,
      "loss": 0.1343,
      "step": 3100
    },
    {
      "epoch": 0.5404941660947151,
      "grad_norm": 4.4329094886779785,
      "learning_rate": 2.4453821508872696e-05,
      "loss": 0.1169,
      "step": 3150
    },
    {
      "epoch": 0.5490734385724091,
      "grad_norm": 1.691129446029663,
      "learning_rate": 2.4368521447798072e-05,
      "loss": 0.1226,
      "step": 3200
    },
    {
      "epoch": 0.557652711050103,
      "grad_norm": 3.6959357261657715,
      "learning_rate": 2.428322138672345e-05,
      "loss": 0.1123,
      "step": 3250
    },
    {
      "epoch": 0.5662319835277968,
      "grad_norm": 1.603962779045105,
      "learning_rate": 2.4197921325648828e-05,
      "loss": 0.1122,
      "step": 3300
    },
    {
      "epoch": 0.5748112560054908,
      "grad_norm": 6.1554365158081055,
      "learning_rate": 2.4112621264574208e-05,
      "loss": 0.12,
      "step": 3350
    },
    {
      "epoch": 0.5833905284831846,
      "grad_norm": 1.1623287200927734,
      "learning_rate": 2.402732120349958e-05,
      "loss": 0.0994,
      "step": 3400
    },
    {
      "epoch": 0.5919698009608785,
      "grad_norm": 1.2726091146469116,
      "learning_rate": 2.394202114242496e-05,
      "loss": 0.1162,
      "step": 3450
    },
    {
      "epoch": 0.6005490734385724,
      "grad_norm": 3.9267945289611816,
      "learning_rate": 2.385672108135034e-05,
      "loss": 0.1169,
      "step": 3500
    },
    {
      "epoch": 0.6091283459162663,
      "grad_norm": 4.713199615478516,
      "learning_rate": 2.3771421020275717e-05,
      "loss": 0.0985,
      "step": 3550
    },
    {
      "epoch": 0.6177076183939602,
      "grad_norm": 3.738814353942871,
      "learning_rate": 2.3686120959201094e-05,
      "loss": 0.1004,
      "step": 3600
    },
    {
      "epoch": 0.6262868908716541,
      "grad_norm": 2.419896125793457,
      "learning_rate": 2.3600820898126474e-05,
      "loss": 0.0992,
      "step": 3650
    },
    {
      "epoch": 0.634866163349348,
      "grad_norm": 1.3262420892715454,
      "learning_rate": 2.351552083705185e-05,
      "loss": 0.106,
      "step": 3700
    },
    {
      "epoch": 0.6434454358270418,
      "grad_norm": 2.7025880813598633,
      "learning_rate": 2.3430220775977226e-05,
      "loss": 0.1221,
      "step": 3750
    },
    {
      "epoch": 0.6520247083047358,
      "grad_norm": 2.222634792327881,
      "learning_rate": 2.3344920714902606e-05,
      "loss": 0.1204,
      "step": 3800
    },
    {
      "epoch": 0.6606039807824297,
      "grad_norm": 0.8120273947715759,
      "learning_rate": 2.3259620653827986e-05,
      "loss": 0.1078,
      "step": 3850
    },
    {
      "epoch": 0.6691832532601235,
      "grad_norm": 3.6548688411712646,
      "learning_rate": 2.3174320592753362e-05,
      "loss": 0.0908,
      "step": 3900
    },
    {
      "epoch": 0.6777625257378175,
      "grad_norm": 5.146215915679932,
      "learning_rate": 2.308902053167874e-05,
      "loss": 0.1088,
      "step": 3950
    },
    {
      "epoch": 0.6863417982155113,
      "grad_norm": 1.0322614908218384,
      "learning_rate": 2.300372047060412e-05,
      "loss": 0.1106,
      "step": 4000
    },
    {
      "epoch": 0.6949210706932052,
      "grad_norm": 1.411142349243164,
      "learning_rate": 2.2918420409529495e-05,
      "loss": 0.0915,
      "step": 4050
    },
    {
      "epoch": 0.7035003431708992,
      "grad_norm": 1.8429659605026245,
      "learning_rate": 2.283312034845487e-05,
      "loss": 0.1114,
      "step": 4100
    },
    {
      "epoch": 0.712079615648593,
      "grad_norm": 4.855970859527588,
      "learning_rate": 2.274782028738025e-05,
      "loss": 0.1002,
      "step": 4150
    },
    {
      "epoch": 0.7206588881262869,
      "grad_norm": 1.027449131011963,
      "learning_rate": 2.2662520226305628e-05,
      "loss": 0.0937,
      "step": 4200
    },
    {
      "epoch": 0.7292381606039808,
      "grad_norm": 0.6775486469268799,
      "learning_rate": 2.2577220165231008e-05,
      "loss": 0.1029,
      "step": 4250
    },
    {
      "epoch": 0.7378174330816747,
      "grad_norm": 2.4649312496185303,
      "learning_rate": 2.2491920104156384e-05,
      "loss": 0.0892,
      "step": 4300
    },
    {
      "epoch": 0.7463967055593685,
      "grad_norm": 2.341019630432129,
      "learning_rate": 2.240662004308176e-05,
      "loss": 0.1076,
      "step": 4350
    },
    {
      "epoch": 0.7549759780370625,
      "grad_norm": 2.314638614654541,
      "learning_rate": 2.232131998200714e-05,
      "loss": 0.1262,
      "step": 4400
    },
    {
      "epoch": 0.7635552505147564,
      "grad_norm": 5.905087947845459,
      "learning_rate": 2.2236019920932517e-05,
      "loss": 0.0985,
      "step": 4450
    },
    {
      "epoch": 0.7721345229924502,
      "grad_norm": 1.9624570608139038,
      "learning_rate": 2.2150719859857893e-05,
      "loss": 0.0927,
      "step": 4500
    },
    {
      "epoch": 0.7807137954701441,
      "grad_norm": 3.06522536277771,
      "learning_rate": 2.2065419798783273e-05,
      "loss": 0.092,
      "step": 4550
    },
    {
      "epoch": 0.789293067947838,
      "grad_norm": 15.018674850463867,
      "learning_rate": 2.1980119737708653e-05,
      "loss": 0.0843,
      "step": 4600
    },
    {
      "epoch": 0.7978723404255319,
      "grad_norm": 0.4016372859477997,
      "learning_rate": 2.1894819676634026e-05,
      "loss": 0.0976,
      "step": 4650
    },
    {
      "epoch": 0.8064516129032258,
      "grad_norm": 3.451840400695801,
      "learning_rate": 2.1809519615559406e-05,
      "loss": 0.0897,
      "step": 4700
    },
    {
      "epoch": 0.8150308853809197,
      "grad_norm": 2.2276763916015625,
      "learning_rate": 2.1724219554484786e-05,
      "loss": 0.0848,
      "step": 4750
    },
    {
      "epoch": 0.8236101578586136,
      "grad_norm": 3.2231605052948,
      "learning_rate": 2.1638919493410162e-05,
      "loss": 0.0881,
      "step": 4800
    },
    {
      "epoch": 0.8321894303363074,
      "grad_norm": 2.058677911758423,
      "learning_rate": 2.155361943233554e-05,
      "loss": 0.0924,
      "step": 4850
    },
    {
      "epoch": 0.8407687028140014,
      "grad_norm": 2.706397771835327,
      "learning_rate": 2.146831937126092e-05,
      "loss": 0.0801,
      "step": 4900
    },
    {
      "epoch": 0.8493479752916953,
      "grad_norm": 0.5991335511207581,
      "learning_rate": 2.1383019310186298e-05,
      "loss": 0.0805,
      "step": 4950
    },
    {
      "epoch": 0.8579272477693891,
      "grad_norm": 1.318806529045105,
      "learning_rate": 2.129771924911167e-05,
      "loss": 0.0928,
      "step": 5000
    },
    {
      "epoch": 0.8665065202470831,
      "grad_norm": 1.1170177459716797,
      "learning_rate": 2.121241918803705e-05,
      "loss": 0.0813,
      "step": 5050
    },
    {
      "epoch": 0.8750857927247769,
      "grad_norm": 1.7012202739715576,
      "learning_rate": 2.112711912696243e-05,
      "loss": 0.0744,
      "step": 5100
    },
    {
      "epoch": 0.8836650652024708,
      "grad_norm": 1.3678947687149048,
      "learning_rate": 2.1041819065887804e-05,
      "loss": 0.0796,
      "step": 5150
    },
    {
      "epoch": 0.8922443376801648,
      "grad_norm": 3.3909568786621094,
      "learning_rate": 2.0956519004813184e-05,
      "loss": 0.0777,
      "step": 5200
    },
    {
      "epoch": 0.9008236101578586,
      "grad_norm": 10.503554344177246,
      "learning_rate": 2.0871218943738564e-05,
      "loss": 0.0828,
      "step": 5250
    },
    {
      "epoch": 0.9094028826355525,
      "grad_norm": 4.468387603759766,
      "learning_rate": 2.078591888266394e-05,
      "loss": 0.0946,
      "step": 5300
    },
    {
      "epoch": 0.9179821551132464,
      "grad_norm": 1.7126965522766113,
      "learning_rate": 2.0700618821589316e-05,
      "loss": 0.0796,
      "step": 5350
    },
    {
      "epoch": 0.9265614275909403,
      "grad_norm": 1.1546777486801147,
      "learning_rate": 2.0615318760514696e-05,
      "loss": 0.0808,
      "step": 5400
    },
    {
      "epoch": 0.9351407000686341,
      "grad_norm": 4.384058952331543,
      "learning_rate": 2.0530018699440073e-05,
      "loss": 0.0825,
      "step": 5450
    },
    {
      "epoch": 0.9437199725463281,
      "grad_norm": 13.213790893554688,
      "learning_rate": 2.044471863836545e-05,
      "loss": 0.0742,
      "step": 5500
    },
    {
      "epoch": 0.952299245024022,
      "grad_norm": 3.2073097229003906,
      "learning_rate": 2.035941857729083e-05,
      "loss": 0.0694,
      "step": 5550
    },
    {
      "epoch": 0.9608785175017158,
      "grad_norm": 0.45983681082725525,
      "learning_rate": 2.0274118516216205e-05,
      "loss": 0.0764,
      "step": 5600
    },
    {
      "epoch": 0.9694577899794098,
      "grad_norm": 4.622942924499512,
      "learning_rate": 2.0188818455141585e-05,
      "loss": 0.0845,
      "step": 5650
    },
    {
      "epoch": 0.9780370624571036,
      "grad_norm": 2.2042789459228516,
      "learning_rate": 2.010351839406696e-05,
      "loss": 0.0801,
      "step": 5700
    },
    {
      "epoch": 0.9866163349347975,
      "grad_norm": 0.9155839681625366,
      "learning_rate": 2.0018218332992338e-05,
      "loss": 0.0733,
      "step": 5750
    },
    {
      "epoch": 0.9951956074124915,
      "grad_norm": 7.8264546394348145,
      "learning_rate": 1.9932918271917718e-05,
      "loss": 0.0842,
      "step": 5800
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9738668517430997,
      "eval_f1": 0.9684326225810174,
      "eval_loss": 0.08907946944236755,
      "eval_precision": 0.9666298798947052,
      "eval_recall": 0.9704185076689532,
      "eval_runtime": 18537.0368,
      "eval_samples_per_second": 8.084,
      "eval_steps_per_second": 0.067,
      "step": 5828
    },
    {
      "epoch": 1.0037748798901853,
      "grad_norm": 2.9848735332489014,
      "learning_rate": 1.9847618210843098e-05,
      "loss": 0.0875,
      "step": 5850
    },
    {
      "epoch": 1.0123541523678792,
      "grad_norm": 4.016339302062988,
      "learning_rate": 1.9762318149768474e-05,
      "loss": 0.0705,
      "step": 5900
    },
    {
      "epoch": 1.020933424845573,
      "grad_norm": 3.930040121078491,
      "learning_rate": 1.967701808869385e-05,
      "loss": 0.062,
      "step": 5950
    },
    {
      "epoch": 1.029512697323267,
      "grad_norm": 1.5871084928512573,
      "learning_rate": 1.959171802761923e-05,
      "loss": 0.0676,
      "step": 6000
    },
    {
      "epoch": 1.038091969800961,
      "grad_norm": 0.9730846881866455,
      "learning_rate": 1.9506417966544607e-05,
      "loss": 0.0561,
      "step": 6050
    },
    {
      "epoch": 1.0466712422786548,
      "grad_norm": 5.793031215667725,
      "learning_rate": 1.9421117905469983e-05,
      "loss": 0.0898,
      "step": 6100
    },
    {
      "epoch": 1.0552505147563487,
      "grad_norm": 4.176580429077148,
      "learning_rate": 1.9335817844395363e-05,
      "loss": 0.0596,
      "step": 6150
    },
    {
      "epoch": 1.0638297872340425,
      "grad_norm": 4.479475021362305,
      "learning_rate": 1.9250517783320743e-05,
      "loss": 0.0714,
      "step": 6200
    },
    {
      "epoch": 1.0724090597117364,
      "grad_norm": 0.7263244986534119,
      "learning_rate": 1.9165217722246116e-05,
      "loss": 0.0635,
      "step": 6250
    },
    {
      "epoch": 1.0809883321894302,
      "grad_norm": 4.070072650909424,
      "learning_rate": 1.9079917661171496e-05,
      "loss": 0.0768,
      "step": 6300
    },
    {
      "epoch": 1.0895676046671243,
      "grad_norm": 3.4311060905456543,
      "learning_rate": 1.8994617600096876e-05,
      "loss": 0.065,
      "step": 6350
    },
    {
      "epoch": 1.0981468771448182,
      "grad_norm": 3.0447745323181152,
      "learning_rate": 1.890931753902225e-05,
      "loss": 0.0642,
      "step": 6400
    },
    {
      "epoch": 1.106726149622512,
      "grad_norm": 4.6124773025512695,
      "learning_rate": 1.882401747794763e-05,
      "loss": 0.0703,
      "step": 6450
    },
    {
      "epoch": 1.115305422100206,
      "grad_norm": 7.133955001831055,
      "learning_rate": 1.873871741687301e-05,
      "loss": 0.0583,
      "step": 6500
    },
    {
      "epoch": 1.1238846945778997,
      "grad_norm": 4.7028679847717285,
      "learning_rate": 1.8653417355798385e-05,
      "loss": 0.059,
      "step": 6550
    },
    {
      "epoch": 1.1324639670555936,
      "grad_norm": 14.942498207092285,
      "learning_rate": 1.856811729472376e-05,
      "loss": 0.0693,
      "step": 6600
    },
    {
      "epoch": 1.1410432395332877,
      "grad_norm": 1.2514740228652954,
      "learning_rate": 1.848281723364914e-05,
      "loss": 0.0616,
      "step": 6650
    },
    {
      "epoch": 1.1496225120109815,
      "grad_norm": 1.9161474704742432,
      "learning_rate": 1.8397517172574518e-05,
      "loss": 0.0649,
      "step": 6700
    },
    {
      "epoch": 1.1582017844886754,
      "grad_norm": 1.4215682744979858,
      "learning_rate": 1.8312217111499894e-05,
      "loss": 0.0659,
      "step": 6750
    },
    {
      "epoch": 1.1667810569663692,
      "grad_norm": 1.062958002090454,
      "learning_rate": 1.8226917050425274e-05,
      "loss": 0.0807,
      "step": 6800
    },
    {
      "epoch": 1.175360329444063,
      "grad_norm": 3.5092506408691406,
      "learning_rate": 1.814161698935065e-05,
      "loss": 0.0491,
      "step": 6850
    },
    {
      "epoch": 1.183939601921757,
      "grad_norm": 0.8073863387107849,
      "learning_rate": 1.805631692827603e-05,
      "loss": 0.0577,
      "step": 6900
    },
    {
      "epoch": 1.1925188743994508,
      "grad_norm": 0.24561022222042084,
      "learning_rate": 1.7971016867201406e-05,
      "loss": 0.0726,
      "step": 6950
    },
    {
      "epoch": 1.201098146877145,
      "grad_norm": 3.5913755893707275,
      "learning_rate": 1.7885716806126783e-05,
      "loss": 0.0625,
      "step": 7000
    },
    {
      "epoch": 1.2096774193548387,
      "grad_norm": 3.0424704551696777,
      "learning_rate": 1.7800416745052163e-05,
      "loss": 0.0476,
      "step": 7050
    },
    {
      "epoch": 1.2182566918325326,
      "grad_norm": 3.3686938285827637,
      "learning_rate": 1.771511668397754e-05,
      "loss": 0.063,
      "step": 7100
    },
    {
      "epoch": 1.2268359643102265,
      "grad_norm": 3.3201141357421875,
      "learning_rate": 1.762981662290292e-05,
      "loss": 0.055,
      "step": 7150
    },
    {
      "epoch": 1.2354152367879203,
      "grad_norm": 4.2918806076049805,
      "learning_rate": 1.7544516561828295e-05,
      "loss": 0.0613,
      "step": 7200
    },
    {
      "epoch": 1.2439945092656144,
      "grad_norm": 1.2068136930465698,
      "learning_rate": 1.7459216500753675e-05,
      "loss": 0.0693,
      "step": 7250
    },
    {
      "epoch": 1.2525737817433082,
      "grad_norm": 0.379905104637146,
      "learning_rate": 1.7373916439679052e-05,
      "loss": 0.0595,
      "step": 7300
    },
    {
      "epoch": 1.261153054221002,
      "grad_norm": 8.084521293640137,
      "learning_rate": 1.7288616378604428e-05,
      "loss": 0.0603,
      "step": 7350
    },
    {
      "epoch": 1.269732326698696,
      "grad_norm": 3.6396636962890625,
      "learning_rate": 1.7203316317529808e-05,
      "loss": 0.0581,
      "step": 7400
    },
    {
      "epoch": 1.2783115991763898,
      "grad_norm": 1.3121339082717896,
      "learning_rate": 1.7118016256455188e-05,
      "loss": 0.0659,
      "step": 7450
    },
    {
      "epoch": 1.2868908716540837,
      "grad_norm": 4.1330389976501465,
      "learning_rate": 1.703271619538056e-05,
      "loss": 0.0737,
      "step": 7500
    },
    {
      "epoch": 1.2954701441317775,
      "grad_norm": 0.7885205745697021,
      "learning_rate": 1.694741613430594e-05,
      "loss": 0.0738,
      "step": 7550
    },
    {
      "epoch": 1.3040494166094714,
      "grad_norm": 10.833076477050781,
      "learning_rate": 1.686211607323132e-05,
      "loss": 0.0641,
      "step": 7600
    },
    {
      "epoch": 1.3126286890871655,
      "grad_norm": 1.5287797451019287,
      "learning_rate": 1.6776816012156694e-05,
      "loss": 0.0597,
      "step": 7650
    },
    {
      "epoch": 1.3212079615648593,
      "grad_norm": 1.9522957801818848,
      "learning_rate": 1.6691515951082073e-05,
      "loss": 0.0566,
      "step": 7700
    },
    {
      "epoch": 1.3297872340425532,
      "grad_norm": 2.7403032779693604,
      "learning_rate": 1.6606215890007453e-05,
      "loss": 0.058,
      "step": 7750
    },
    {
      "epoch": 1.338366506520247,
      "grad_norm": 3.4332358837127686,
      "learning_rate": 1.652091582893283e-05,
      "loss": 0.0546,
      "step": 7800
    },
    {
      "epoch": 1.346945778997941,
      "grad_norm": 3.3321774005889893,
      "learning_rate": 1.6435615767858206e-05,
      "loss": 0.0529,
      "step": 7850
    },
    {
      "epoch": 1.355525051475635,
      "grad_norm": 0.21167252957820892,
      "learning_rate": 1.6350315706783586e-05,
      "loss": 0.0634,
      "step": 7900
    },
    {
      "epoch": 1.3641043239533288,
      "grad_norm": 2.230051279067993,
      "learning_rate": 1.6265015645708962e-05,
      "loss": 0.0492,
      "step": 7950
    },
    {
      "epoch": 1.3726835964310227,
      "grad_norm": 3.473155975341797,
      "learning_rate": 1.617971558463434e-05,
      "loss": 0.0592,
      "step": 8000
    },
    {
      "epoch": 1.3812628689087165,
      "grad_norm": 1.0890822410583496,
      "learning_rate": 1.609441552355972e-05,
      "loss": 0.0616,
      "step": 8050
    },
    {
      "epoch": 1.3898421413864104,
      "grad_norm": 4.912774085998535,
      "learning_rate": 1.6009115462485095e-05,
      "loss": 0.0531,
      "step": 8100
    },
    {
      "epoch": 1.3984214138641042,
      "grad_norm": 14.042840957641602,
      "learning_rate": 1.5923815401410475e-05,
      "loss": 0.0459,
      "step": 8150
    },
    {
      "epoch": 1.407000686341798,
      "grad_norm": 2.4898171424865723,
      "learning_rate": 1.583851534033585e-05,
      "loss": 0.055,
      "step": 8200
    },
    {
      "epoch": 1.4155799588194922,
      "grad_norm": 0.8119410276412964,
      "learning_rate": 1.575321527926123e-05,
      "loss": 0.062,
      "step": 8250
    },
    {
      "epoch": 1.424159231297186,
      "grad_norm": 8.960271835327148,
      "learning_rate": 1.5667915218186608e-05,
      "loss": 0.0449,
      "step": 8300
    },
    {
      "epoch": 1.4327385037748799,
      "grad_norm": 0.8286723494529724,
      "learning_rate": 1.5582615157111984e-05,
      "loss": 0.0765,
      "step": 8350
    },
    {
      "epoch": 1.4413177762525737,
      "grad_norm": 5.479249954223633,
      "learning_rate": 1.5497315096037364e-05,
      "loss": 0.0573,
      "step": 8400
    },
    {
      "epoch": 1.4498970487302676,
      "grad_norm": 1.0199456214904785,
      "learning_rate": 1.541201503496274e-05,
      "loss": 0.0514,
      "step": 8450
    },
    {
      "epoch": 1.4584763212079617,
      "grad_norm": 1.6616092920303345,
      "learning_rate": 1.532671497388812e-05,
      "loss": 0.0461,
      "step": 8500
    },
    {
      "epoch": 1.4670555936856555,
      "grad_norm": 0.5194264054298401,
      "learning_rate": 1.5241414912813495e-05,
      "loss": 0.0592,
      "step": 8550
    },
    {
      "epoch": 1.4756348661633494,
      "grad_norm": 5.98361873626709,
      "learning_rate": 1.5156114851738875e-05,
      "loss": 0.0471,
      "step": 8600
    },
    {
      "epoch": 1.4842141386410432,
      "grad_norm": 1.1413031816482544,
      "learning_rate": 1.5070814790664253e-05,
      "loss": 0.0525,
      "step": 8650
    },
    {
      "epoch": 1.492793411118737,
      "grad_norm": 1.6437413692474365,
      "learning_rate": 1.4985514729589628e-05,
      "loss": 0.056,
      "step": 8700
    },
    {
      "epoch": 1.501372683596431,
      "grad_norm": 15.980562210083008,
      "learning_rate": 1.4900214668515007e-05,
      "loss": 0.0441,
      "step": 8750
    },
    {
      "epoch": 1.5099519560741248,
      "grad_norm": 4.5075764656066895,
      "learning_rate": 1.4814914607440386e-05,
      "loss": 0.0445,
      "step": 8800
    },
    {
      "epoch": 1.5185312285518187,
      "grad_norm": 0.4847867786884308,
      "learning_rate": 1.4729614546365764e-05,
      "loss": 0.0418,
      "step": 8850
    },
    {
      "epoch": 1.5271105010295127,
      "grad_norm": 3.8441989421844482,
      "learning_rate": 1.464431448529114e-05,
      "loss": 0.0379,
      "step": 8900
    },
    {
      "epoch": 1.5356897735072066,
      "grad_norm": 7.906745910644531,
      "learning_rate": 1.4559014424216518e-05,
      "loss": 0.0447,
      "step": 8950
    },
    {
      "epoch": 1.5442690459849004,
      "grad_norm": 6.357057094573975,
      "learning_rate": 1.4473714363141896e-05,
      "loss": 0.0473,
      "step": 9000
    },
    {
      "epoch": 1.5528483184625945,
      "grad_norm": 4.304576873779297,
      "learning_rate": 1.4388414302067273e-05,
      "loss": 0.0332,
      "step": 9050
    },
    {
      "epoch": 1.5614275909402884,
      "grad_norm": 1.8683431148529053,
      "learning_rate": 1.4303114240992651e-05,
      "loss": 0.0592,
      "step": 9100
    },
    {
      "epoch": 1.5700068634179822,
      "grad_norm": 1.5412955284118652,
      "learning_rate": 1.421781417991803e-05,
      "loss": 0.0406,
      "step": 9150
    },
    {
      "epoch": 1.578586135895676,
      "grad_norm": 6.885437488555908,
      "learning_rate": 1.4132514118843407e-05,
      "loss": 0.0566,
      "step": 9200
    },
    {
      "epoch": 1.58716540837337,
      "grad_norm": 1.5420281887054443,
      "learning_rate": 1.4047214057768785e-05,
      "loss": 0.059,
      "step": 9250
    },
    {
      "epoch": 1.5957446808510638,
      "grad_norm": 2.6307153701782227,
      "learning_rate": 1.3961913996694163e-05,
      "loss": 0.0459,
      "step": 9300
    },
    {
      "epoch": 1.6043239533287577,
      "grad_norm": 14.386608123779297,
      "learning_rate": 1.3876613935619542e-05,
      "loss": 0.0487,
      "step": 9350
    },
    {
      "epoch": 1.6129032258064515,
      "grad_norm": 6.603262901306152,
      "learning_rate": 1.3791313874544918e-05,
      "loss": 0.0562,
      "step": 9400
    },
    {
      "epoch": 1.6214824982841454,
      "grad_norm": 0.1971052885055542,
      "learning_rate": 1.3706013813470296e-05,
      "loss": 0.0528,
      "step": 9450
    },
    {
      "epoch": 1.6300617707618394,
      "grad_norm": 0.8138952255249023,
      "learning_rate": 1.3620713752395674e-05,
      "loss": 0.0431,
      "step": 9500
    },
    {
      "epoch": 1.6386410432395333,
      "grad_norm": 0.801052987575531,
      "learning_rate": 1.3535413691321052e-05,
      "loss": 0.0394,
      "step": 9550
    },
    {
      "epoch": 1.6472203157172272,
      "grad_norm": 0.5888530611991882,
      "learning_rate": 1.345011363024643e-05,
      "loss": 0.0508,
      "step": 9600
    },
    {
      "epoch": 1.6557995881949212,
      "grad_norm": 0.08969680219888687,
      "learning_rate": 1.3364813569171807e-05,
      "loss": 0.046,
      "step": 9650
    },
    {
      "epoch": 1.664378860672615,
      "grad_norm": 0.07577924430370331,
      "learning_rate": 1.3279513508097187e-05,
      "loss": 0.0498,
      "step": 9700
    },
    {
      "epoch": 1.672958133150309,
      "grad_norm": 0.42313164472579956,
      "learning_rate": 1.3194213447022563e-05,
      "loss": 0.0427,
      "step": 9750
    },
    {
      "epoch": 1.6815374056280028,
      "grad_norm": 0.685463011264801,
      "learning_rate": 1.310891338594794e-05,
      "loss": 0.0516,
      "step": 9800
    },
    {
      "epoch": 1.6901166781056967,
      "grad_norm": 18.508262634277344,
      "learning_rate": 1.302361332487332e-05,
      "loss": 0.047,
      "step": 9850
    },
    {
      "epoch": 1.6986959505833905,
      "grad_norm": 0.28520503640174866,
      "learning_rate": 1.2938313263798696e-05,
      "loss": 0.0498,
      "step": 9900
    },
    {
      "epoch": 1.7072752230610844,
      "grad_norm": 6.464752197265625,
      "learning_rate": 1.2853013202724074e-05,
      "loss": 0.0564,
      "step": 9950
    },
    {
      "epoch": 1.7158544955387782,
      "grad_norm": 0.4118041396141052,
      "learning_rate": 1.2767713141649452e-05,
      "loss": 0.0363,
      "step": 10000
    },
    {
      "epoch": 1.724433768016472,
      "grad_norm": 1.1244803667068481,
      "learning_rate": 1.268241308057483e-05,
      "loss": 0.0417,
      "step": 10050
    },
    {
      "epoch": 1.733013040494166,
      "grad_norm": 1.9550292491912842,
      "learning_rate": 1.2597113019500207e-05,
      "loss": 0.0391,
      "step": 10100
    },
    {
      "epoch": 1.74159231297186,
      "grad_norm": 7.4150896072387695,
      "learning_rate": 1.2511812958425587e-05,
      "loss": 0.0569,
      "step": 10150
    },
    {
      "epoch": 1.7501715854495539,
      "grad_norm": 1.9037295579910278,
      "learning_rate": 1.2426512897350963e-05,
      "loss": 0.0464,
      "step": 10200
    },
    {
      "epoch": 1.7587508579272477,
      "grad_norm": 0.23840172588825226,
      "learning_rate": 1.2341212836276341e-05,
      "loss": 0.0432,
      "step": 10250
    },
    {
      "epoch": 1.7673301304049418,
      "grad_norm": 7.41839599609375,
      "learning_rate": 1.225591277520172e-05,
      "loss": 0.0406,
      "step": 10300
    },
    {
      "epoch": 1.7759094028826357,
      "grad_norm": 4.482361316680908,
      "learning_rate": 1.2170612714127096e-05,
      "loss": 0.0588,
      "step": 10350
    },
    {
      "epoch": 1.7844886753603295,
      "grad_norm": 6.949913501739502,
      "learning_rate": 1.2085312653052476e-05,
      "loss": 0.0365,
      "step": 10400
    },
    {
      "epoch": 1.7930679478380234,
      "grad_norm": 1.6383188962936401,
      "learning_rate": 1.2000012591977852e-05,
      "loss": 0.0424,
      "step": 10450
    },
    {
      "epoch": 1.8016472203157172,
      "grad_norm": 7.3747477531433105,
      "learning_rate": 1.191471253090323e-05,
      "loss": 0.041,
      "step": 10500
    },
    {
      "epoch": 1.810226492793411,
      "grad_norm": 8.657013893127441,
      "learning_rate": 1.1829412469828608e-05,
      "loss": 0.0482,
      "step": 10550
    },
    {
      "epoch": 1.818805765271105,
      "grad_norm": 2.558027505874634,
      "learning_rate": 1.1744112408753985e-05,
      "loss": 0.0525,
      "step": 10600
    },
    {
      "epoch": 1.8273850377487988,
      "grad_norm": 0.9755445718765259,
      "learning_rate": 1.1658812347679363e-05,
      "loss": 0.0538,
      "step": 10650
    },
    {
      "epoch": 1.8359643102264926,
      "grad_norm": 4.475901126861572,
      "learning_rate": 1.1573512286604741e-05,
      "loss": 0.0364,
      "step": 10700
    },
    {
      "epoch": 1.8445435827041867,
      "grad_norm": 1.1879812479019165,
      "learning_rate": 1.1488212225530119e-05,
      "loss": 0.0396,
      "step": 10750
    },
    {
      "epoch": 1.8531228551818806,
      "grad_norm": 2.9124765396118164,
      "learning_rate": 1.1402912164455497e-05,
      "loss": 0.04,
      "step": 10800
    },
    {
      "epoch": 1.8617021276595744,
      "grad_norm": 2.512085437774658,
      "learning_rate": 1.1317612103380875e-05,
      "loss": 0.0379,
      "step": 10850
    },
    {
      "epoch": 1.8702814001372685,
      "grad_norm": 0.11163704097270966,
      "learning_rate": 1.1232312042306252e-05,
      "loss": 0.0495,
      "step": 10900
    },
    {
      "epoch": 1.8788606726149624,
      "grad_norm": 0.7135981321334839,
      "learning_rate": 1.1147011981231632e-05,
      "loss": 0.0475,
      "step": 10950
    },
    {
      "epoch": 1.8874399450926562,
      "grad_norm": 6.8315911293029785,
      "learning_rate": 1.1061711920157008e-05,
      "loss": 0.0383,
      "step": 11000
    },
    {
      "epoch": 1.89601921757035,
      "grad_norm": 3.988084316253662,
      "learning_rate": 1.0976411859082385e-05,
      "loss": 0.044,
      "step": 11050
    },
    {
      "epoch": 1.904598490048044,
      "grad_norm": 0.3278500437736511,
      "learning_rate": 1.0891111798007764e-05,
      "loss": 0.0415,
      "step": 11100
    },
    {
      "epoch": 1.9131777625257378,
      "grad_norm": 0.9274600148200989,
      "learning_rate": 1.080581173693314e-05,
      "loss": 0.0438,
      "step": 11150
    },
    {
      "epoch": 1.9217570350034316,
      "grad_norm": 0.7394218444824219,
      "learning_rate": 1.0720511675858519e-05,
      "loss": 0.052,
      "step": 11200
    },
    {
      "epoch": 1.9303363074811255,
      "grad_norm": 0.9948009848594666,
      "learning_rate": 1.0635211614783897e-05,
      "loss": 0.05,
      "step": 11250
    },
    {
      "epoch": 1.9389155799588194,
      "grad_norm": 11.31454849243164,
      "learning_rate": 1.0549911553709275e-05,
      "loss": 0.0459,
      "step": 11300
    },
    {
      "epoch": 1.9474948524365134,
      "grad_norm": 3.2947261333465576,
      "learning_rate": 1.0464611492634653e-05,
      "loss": 0.0422,
      "step": 11350
    },
    {
      "epoch": 1.9560741249142073,
      "grad_norm": 5.970810413360596,
      "learning_rate": 1.037931143156003e-05,
      "loss": 0.0391,
      "step": 11400
    },
    {
      "epoch": 1.9646533973919011,
      "grad_norm": 2.1819467544555664,
      "learning_rate": 1.0294011370485408e-05,
      "loss": 0.0425,
      "step": 11450
    },
    {
      "epoch": 1.9732326698695952,
      "grad_norm": 1.2163760662078857,
      "learning_rate": 1.0208711309410786e-05,
      "loss": 0.0453,
      "step": 11500
    },
    {
      "epoch": 1.981811942347289,
      "grad_norm": 2.4257264137268066,
      "learning_rate": 1.0123411248336164e-05,
      "loss": 0.0425,
      "step": 11550
    },
    {
      "epoch": 1.990391214824983,
      "grad_norm": 0.5423018336296082,
      "learning_rate": 1.003811118726154e-05,
      "loss": 0.0345,
      "step": 11600
    },
    {
      "epoch": 1.9989704873026768,
      "grad_norm": 0.15000107884407043,
      "learning_rate": 9.95281112618692e-06,
      "loss": 0.0374,
      "step": 11650
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9838970156425177,
      "eval_f1": 0.9811835810205238,
      "eval_loss": 0.051451556384563446,
      "eval_precision": 0.9787829391117299,
      "eval_recall": 0.9836921778816476,
      "eval_runtime": 18626.9806,
      "eval_samples_per_second": 8.045,
      "eval_steps_per_second": 0.067,
      "step": 11656
    },
    {
      "epoch": 2.0075497597803706,
      "grad_norm": 2.01762056350708,
      "learning_rate": 9.867511065112297e-06,
      "loss": 0.0334,
      "step": 11700
    },
    {
      "epoch": 2.0161290322580645,
      "grad_norm": 2.046043634414673,
      "learning_rate": 9.782211004037675e-06,
      "loss": 0.0337,
      "step": 11750
    },
    {
      "epoch": 2.0247083047357584,
      "grad_norm": 0.8375492691993713,
      "learning_rate": 9.696910942963053e-06,
      "loss": 0.0328,
      "step": 11800
    },
    {
      "epoch": 2.033287577213452,
      "grad_norm": 0.46168598532676697,
      "learning_rate": 9.61161088188843e-06,
      "loss": 0.0323,
      "step": 11850
    },
    {
      "epoch": 2.041866849691146,
      "grad_norm": 7.769717693328857,
      "learning_rate": 9.52631082081381e-06,
      "loss": 0.0304,
      "step": 11900
    },
    {
      "epoch": 2.05044612216884,
      "grad_norm": 6.810415744781494,
      "learning_rate": 9.441010759739186e-06,
      "loss": 0.0319,
      "step": 11950
    },
    {
      "epoch": 2.059025394646534,
      "grad_norm": 0.4474800229072571,
      "learning_rate": 9.355710698664564e-06,
      "loss": 0.0379,
      "step": 12000
    },
    {
      "epoch": 2.067604667124228,
      "grad_norm": 0.30851608514785767,
      "learning_rate": 9.270410637589942e-06,
      "loss": 0.0433,
      "step": 12050
    },
    {
      "epoch": 2.076183939601922,
      "grad_norm": 0.5136615037918091,
      "learning_rate": 9.18511057651532e-06,
      "loss": 0.0273,
      "step": 12100
    },
    {
      "epoch": 2.084763212079616,
      "grad_norm": 0.3736411929130554,
      "learning_rate": 9.099810515440697e-06,
      "loss": 0.0368,
      "step": 12150
    },
    {
      "epoch": 2.0933424845573096,
      "grad_norm": 0.29784727096557617,
      "learning_rate": 9.014510454366075e-06,
      "loss": 0.0335,
      "step": 12200
    },
    {
      "epoch": 2.1019217570350035,
      "grad_norm": 0.2727375030517578,
      "learning_rate": 8.929210393291453e-06,
      "loss": 0.0276,
      "step": 12250
    },
    {
      "epoch": 2.1105010295126974,
      "grad_norm": 3.9382667541503906,
      "learning_rate": 8.84391033221683e-06,
      "loss": 0.0296,
      "step": 12300
    },
    {
      "epoch": 2.119080301990391,
      "grad_norm": 0.2823233902454376,
      "learning_rate": 8.75861027114221e-06,
      "loss": 0.0311,
      "step": 12350
    },
    {
      "epoch": 2.127659574468085,
      "grad_norm": 6.488738536834717,
      "learning_rate": 8.673310210067586e-06,
      "loss": 0.0344,
      "step": 12400
    },
    {
      "epoch": 2.136238846945779,
      "grad_norm": 0.25111648440361023,
      "learning_rate": 8.588010148992964e-06,
      "loss": 0.0438,
      "step": 12450
    },
    {
      "epoch": 2.144818119423473,
      "grad_norm": 0.5381084084510803,
      "learning_rate": 8.502710087918342e-06,
      "loss": 0.0281,
      "step": 12500
    },
    {
      "epoch": 2.1533973919011666,
      "grad_norm": 0.1269361972808838,
      "learning_rate": 8.417410026843718e-06,
      "loss": 0.0356,
      "step": 12550
    },
    {
      "epoch": 2.1619766643788605,
      "grad_norm": 0.6182725429534912,
      "learning_rate": 8.332109965769098e-06,
      "loss": 0.0362,
      "step": 12600
    },
    {
      "epoch": 2.1705559368565543,
      "grad_norm": 0.19482040405273438,
      "learning_rate": 8.246809904694475e-06,
      "loss": 0.0366,
      "step": 12650
    },
    {
      "epoch": 2.1791352093342486,
      "grad_norm": 0.15649516880512238,
      "learning_rate": 8.161509843619853e-06,
      "loss": 0.0417,
      "step": 12700
    },
    {
      "epoch": 2.1877144818119425,
      "grad_norm": 0.915949285030365,
      "learning_rate": 8.076209782545231e-06,
      "loss": 0.0359,
      "step": 12750
    },
    {
      "epoch": 2.1962937542896364,
      "grad_norm": 2.5879271030426025,
      "learning_rate": 7.990909721470609e-06,
      "loss": 0.0382,
      "step": 12800
    },
    {
      "epoch": 2.20487302676733,
      "grad_norm": 15.06293773651123,
      "learning_rate": 7.905609660395985e-06,
      "loss": 0.0285,
      "step": 12850
    },
    {
      "epoch": 2.213452299245024,
      "grad_norm": 0.887763500213623,
      "learning_rate": 7.820309599321365e-06,
      "loss": 0.0279,
      "step": 12900
    },
    {
      "epoch": 2.222031571722718,
      "grad_norm": 0.17395181953907013,
      "learning_rate": 7.735009538246742e-06,
      "loss": 0.0277,
      "step": 12950
    },
    {
      "epoch": 2.230610844200412,
      "grad_norm": 0.11719028651714325,
      "learning_rate": 7.64970947717212e-06,
      "loss": 0.0287,
      "step": 13000
    },
    {
      "epoch": 2.2391901166781056,
      "grad_norm": 7.017211437225342,
      "learning_rate": 7.564409416097498e-06,
      "loss": 0.0254,
      "step": 13050
    },
    {
      "epoch": 2.2477693891557995,
      "grad_norm": 12.104506492614746,
      "learning_rate": 7.479109355022875e-06,
      "loss": 0.0261,
      "step": 13100
    },
    {
      "epoch": 2.2563486616334933,
      "grad_norm": 3.4512875080108643,
      "learning_rate": 7.393809293948253e-06,
      "loss": 0.032,
      "step": 13150
    },
    {
      "epoch": 2.264927934111187,
      "grad_norm": 0.4946325123310089,
      "learning_rate": 7.308509232873631e-06,
      "loss": 0.0336,
      "step": 13200
    },
    {
      "epoch": 2.2735072065888815,
      "grad_norm": 10.309986114501953,
      "learning_rate": 7.22320917179901e-06,
      "loss": 0.0373,
      "step": 13250
    },
    {
      "epoch": 2.2820864790665754,
      "grad_norm": 6.826344013214111,
      "learning_rate": 7.137909110724386e-06,
      "loss": 0.0339,
      "step": 13300
    },
    {
      "epoch": 2.290665751544269,
      "grad_norm": 0.2137148082256317,
      "learning_rate": 7.052609049649764e-06,
      "loss": 0.0226,
      "step": 13350
    },
    {
      "epoch": 2.299245024021963,
      "grad_norm": 0.20876581966876984,
      "learning_rate": 6.967308988575142e-06,
      "loss": 0.0204,
      "step": 13400
    },
    {
      "epoch": 2.307824296499657,
      "grad_norm": 0.07637573033571243,
      "learning_rate": 6.8820089275005205e-06,
      "loss": 0.0267,
      "step": 13450
    },
    {
      "epoch": 2.316403568977351,
      "grad_norm": 0.4099585711956024,
      "learning_rate": 6.796708866425898e-06,
      "loss": 0.0321,
      "step": 13500
    },
    {
      "epoch": 2.3249828414550446,
      "grad_norm": 0.06974878907203674,
      "learning_rate": 6.711408805351275e-06,
      "loss": 0.0355,
      "step": 13550
    },
    {
      "epoch": 2.3335621139327385,
      "grad_norm": 12.367549896240234,
      "learning_rate": 6.626108744276653e-06,
      "loss": 0.0242,
      "step": 13600
    },
    {
      "epoch": 2.3421413864104323,
      "grad_norm": 0.4452120065689087,
      "learning_rate": 6.5408086832020305e-06,
      "loss": 0.0235,
      "step": 13650
    },
    {
      "epoch": 2.350720658888126,
      "grad_norm": 0.15294010937213898,
      "learning_rate": 6.455508622127409e-06,
      "loss": 0.0212,
      "step": 13700
    },
    {
      "epoch": 2.35929993136582,
      "grad_norm": 0.04842083528637886,
      "learning_rate": 6.370208561052787e-06,
      "loss": 0.0266,
      "step": 13750
    },
    {
      "epoch": 2.367879203843514,
      "grad_norm": 0.22757312655448914,
      "learning_rate": 6.284908499978165e-06,
      "loss": 0.0337,
      "step": 13800
    },
    {
      "epoch": 2.3764584763212078,
      "grad_norm": 12.728944778442383,
      "learning_rate": 6.199608438903542e-06,
      "loss": 0.0251,
      "step": 13850
    },
    {
      "epoch": 2.3850377487989016,
      "grad_norm": 15.206329345703125,
      "learning_rate": 6.11430837782892e-06,
      "loss": 0.0302,
      "step": 13900
    },
    {
      "epoch": 2.393617021276596,
      "grad_norm": 0.20897050201892853,
      "learning_rate": 6.0290083167542975e-06,
      "loss": 0.0369,
      "step": 13950
    },
    {
      "epoch": 2.40219629375429,
      "grad_norm": 10.286567687988281,
      "learning_rate": 5.943708255679676e-06,
      "loss": 0.0269,
      "step": 14000
    },
    {
      "epoch": 2.4107755662319836,
      "grad_norm": 0.032022565603256226,
      "learning_rate": 5.858408194605053e-06,
      "loss": 0.0241,
      "step": 14050
    },
    {
      "epoch": 2.4193548387096775,
      "grad_norm": 0.10127320140600204,
      "learning_rate": 5.773108133530431e-06,
      "loss": 0.0272,
      "step": 14100
    },
    {
      "epoch": 2.4279341111873713,
      "grad_norm": 4.470780849456787,
      "learning_rate": 5.687808072455809e-06,
      "loss": 0.0276,
      "step": 14150
    },
    {
      "epoch": 2.436513383665065,
      "grad_norm": 0.33933791518211365,
      "learning_rate": 5.6025080113811865e-06,
      "loss": 0.0193,
      "step": 14200
    },
    {
      "epoch": 2.445092656142759,
      "grad_norm": 5.35098934173584,
      "learning_rate": 5.517207950306565e-06,
      "loss": 0.0228,
      "step": 14250
    },
    {
      "epoch": 2.453671928620453,
      "grad_norm": 0.3442383110523224,
      "learning_rate": 5.431907889231942e-06,
      "loss": 0.0221,
      "step": 14300
    },
    {
      "epoch": 2.4622512010981468,
      "grad_norm": 0.26784607768058777,
      "learning_rate": 5.34660782815732e-06,
      "loss": 0.0316,
      "step": 14350
    },
    {
      "epoch": 2.4708304735758406,
      "grad_norm": 0.28714174032211304,
      "learning_rate": 5.261307767082697e-06,
      "loss": 0.0314,
      "step": 14400
    },
    {
      "epoch": 2.4794097460535345,
      "grad_norm": 0.34035369753837585,
      "learning_rate": 5.1760077060080755e-06,
      "loss": 0.0232,
      "step": 14450
    },
    {
      "epoch": 2.487989018531229,
      "grad_norm": 0.42905911803245544,
      "learning_rate": 5.090707644933454e-06,
      "loss": 0.0243,
      "step": 14500
    },
    {
      "epoch": 2.4965682910089226,
      "grad_norm": 3.4097864627838135,
      "learning_rate": 5.005407583858831e-06,
      "loss": 0.0361,
      "step": 14550
    },
    {
      "epoch": 2.5051475634866165,
      "grad_norm": 0.06771112978458405,
      "learning_rate": 4.920107522784209e-06,
      "loss": 0.0262,
      "step": 14600
    },
    {
      "epoch": 2.5137268359643103,
      "grad_norm": 1.624481439590454,
      "learning_rate": 4.834807461709587e-06,
      "loss": 0.0355,
      "step": 14650
    },
    {
      "epoch": 2.522306108442004,
      "grad_norm": 0.37747958302497864,
      "learning_rate": 4.7495074006349644e-06,
      "loss": 0.0268,
      "step": 14700
    },
    {
      "epoch": 2.530885380919698,
      "grad_norm": 0.3767854869365692,
      "learning_rate": 4.664207339560342e-06,
      "loss": 0.0318,
      "step": 14750
    },
    {
      "epoch": 2.539464653397392,
      "grad_norm": 0.2008543610572815,
      "learning_rate": 4.57890727848572e-06,
      "loss": 0.0198,
      "step": 14800
    },
    {
      "epoch": 2.5480439258750858,
      "grad_norm": 0.07697116583585739,
      "learning_rate": 4.493607217411098e-06,
      "loss": 0.0301,
      "step": 14850
    },
    {
      "epoch": 2.5566231983527796,
      "grad_norm": 0.4535163640975952,
      "learning_rate": 4.408307156336476e-06,
      "loss": 0.0259,
      "step": 14900
    },
    {
      "epoch": 2.5652024708304735,
      "grad_norm": 0.541304886341095,
      "learning_rate": 4.323007095261853e-06,
      "loss": 0.0362,
      "step": 14950
    },
    {
      "epoch": 2.5737817433081673,
      "grad_norm": 0.14615647494792938,
      "learning_rate": 4.2377070341872315e-06,
      "loss": 0.0253,
      "step": 15000
    },
    {
      "epoch": 2.582361015785861,
      "grad_norm": 0.5535499453544617,
      "learning_rate": 4.15240697311261e-06,
      "loss": 0.0259,
      "step": 15050
    },
    {
      "epoch": 2.590940288263555,
      "grad_norm": 0.021947622299194336,
      "learning_rate": 4.067106912037987e-06,
      "loss": 0.026,
      "step": 15100
    },
    {
      "epoch": 2.599519560741249,
      "grad_norm": 0.7331445217132568,
      "learning_rate": 3.981806850963364e-06,
      "loss": 0.0233,
      "step": 15150
    },
    {
      "epoch": 2.6080988332189428,
      "grad_norm": 0.23031631112098694,
      "learning_rate": 3.896506789888742e-06,
      "loss": 0.0302,
      "step": 15200
    },
    {
      "epoch": 2.616678105696637,
      "grad_norm": 0.26916033029556274,
      "learning_rate": 3.81120672881412e-06,
      "loss": 0.0252,
      "step": 15250
    },
    {
      "epoch": 2.625257378174331,
      "grad_norm": 0.27593913674354553,
      "learning_rate": 3.7259066677394982e-06,
      "loss": 0.0312,
      "step": 15300
    },
    {
      "epoch": 2.6338366506520248,
      "grad_norm": 0.04836516082286835,
      "learning_rate": 3.640606606664876e-06,
      "loss": 0.028,
      "step": 15350
    },
    {
      "epoch": 2.6424159231297186,
      "grad_norm": 3.2638802528381348,
      "learning_rate": 3.5553065455902536e-06,
      "loss": 0.024,
      "step": 15400
    },
    {
      "epoch": 2.6509951956074125,
      "grad_norm": 1.4294582605361938,
      "learning_rate": 3.4700064845156313e-06,
      "loss": 0.0266,
      "step": 15450
    },
    {
      "epoch": 2.6595744680851063,
      "grad_norm": 0.22321423888206482,
      "learning_rate": 3.3847064234410095e-06,
      "loss": 0.0296,
      "step": 15500
    },
    {
      "epoch": 2.6681537405628,
      "grad_norm": 1.185016393661499,
      "learning_rate": 3.299406362366387e-06,
      "loss": 0.0308,
      "step": 15550
    },
    {
      "epoch": 2.676733013040494,
      "grad_norm": 0.46208426356315613,
      "learning_rate": 3.214106301291765e-06,
      "loss": 0.0209,
      "step": 15600
    },
    {
      "epoch": 2.685312285518188,
      "grad_norm": 0.11879425495862961,
      "learning_rate": 3.1288062402171426e-06,
      "loss": 0.034,
      "step": 15650
    },
    {
      "epoch": 2.693891557995882,
      "grad_norm": 3.3961591720581055,
      "learning_rate": 3.0435061791425203e-06,
      "loss": 0.0332,
      "step": 15700
    },
    {
      "epoch": 2.702470830473576,
      "grad_norm": 0.7339129447937012,
      "learning_rate": 2.9582061180678984e-06,
      "loss": 0.0257,
      "step": 15750
    },
    {
      "epoch": 2.71105010295127,
      "grad_norm": 2.051957130432129,
      "learning_rate": 2.8729060569932757e-06,
      "loss": 0.028,
      "step": 15800
    },
    {
      "epoch": 2.7196293754289638,
      "grad_norm": 5.27262020111084,
      "learning_rate": 2.787605995918654e-06,
      "loss": 0.0313,
      "step": 15850
    },
    {
      "epoch": 2.7282086479066576,
      "grad_norm": 0.042808204889297485,
      "learning_rate": 2.7023059348440316e-06,
      "loss": 0.0257,
      "step": 15900
    },
    {
      "epoch": 2.7367879203843515,
      "grad_norm": 3.4226276874542236,
      "learning_rate": 2.6170058737694097e-06,
      "loss": 0.0304,
      "step": 15950
    },
    {
      "epoch": 2.7453671928620453,
      "grad_norm": 5.220726490020752,
      "learning_rate": 2.531705812694787e-06,
      "loss": 0.0267,
      "step": 16000
    },
    {
      "epoch": 2.753946465339739,
      "grad_norm": 0.04856892302632332,
      "learning_rate": 2.446405751620165e-06,
      "loss": 0.0276,
      "step": 16050
    },
    {
      "epoch": 2.762525737817433,
      "grad_norm": 1.096198558807373,
      "learning_rate": 2.361105690545543e-06,
      "loss": 0.0298,
      "step": 16100
    },
    {
      "epoch": 2.771105010295127,
      "grad_norm": 1.0819733142852783,
      "learning_rate": 2.2758056294709205e-06,
      "loss": 0.0259,
      "step": 16150
    },
    {
      "epoch": 2.7796842827728208,
      "grad_norm": 3.789407253265381,
      "learning_rate": 2.1905055683962982e-06,
      "loss": 0.0126,
      "step": 16200
    },
    {
      "epoch": 2.7882635552505146,
      "grad_norm": 1.4312777519226074,
      "learning_rate": 2.105205507321676e-06,
      "loss": 0.0292,
      "step": 16250
    },
    {
      "epoch": 2.7968428277282085,
      "grad_norm": 5.060838222503662,
      "learning_rate": 2.019905446247054e-06,
      "loss": 0.0189,
      "step": 16300
    },
    {
      "epoch": 2.8054221002059023,
      "grad_norm": 0.12984055280685425,
      "learning_rate": 1.934605385172432e-06,
      "loss": 0.0297,
      "step": 16350
    },
    {
      "epoch": 2.814001372683596,
      "grad_norm": 0.15029993653297424,
      "learning_rate": 1.8493053240978093e-06,
      "loss": 0.0193,
      "step": 16400
    },
    {
      "epoch": 2.8225806451612905,
      "grad_norm": 3.6845993995666504,
      "learning_rate": 1.7640052630231872e-06,
      "loss": 0.0402,
      "step": 16450
    },
    {
      "epoch": 2.8311599176389843,
      "grad_norm": 1.3670110702514648,
      "learning_rate": 1.678705201948565e-06,
      "loss": 0.0188,
      "step": 16500
    },
    {
      "epoch": 2.839739190116678,
      "grad_norm": 7.433603286743164,
      "learning_rate": 1.5934051408739428e-06,
      "loss": 0.0208,
      "step": 16550
    },
    {
      "epoch": 2.848318462594372,
      "grad_norm": 1.8984333276748657,
      "learning_rate": 1.5081050797993205e-06,
      "loss": 0.0252,
      "step": 16600
    },
    {
      "epoch": 2.856897735072066,
      "grad_norm": 0.04879800230264664,
      "learning_rate": 1.4228050187246985e-06,
      "loss": 0.0191,
      "step": 16650
    },
    {
      "epoch": 2.8654770075497598,
      "grad_norm": 0.612217903137207,
      "learning_rate": 1.3375049576500762e-06,
      "loss": 0.0257,
      "step": 16700
    },
    {
      "epoch": 2.8740562800274536,
      "grad_norm": 0.3930453658103943,
      "learning_rate": 1.252204896575454e-06,
      "loss": 0.0246,
      "step": 16750
    },
    {
      "epoch": 2.8826355525051475,
      "grad_norm": 5.905318737030029,
      "learning_rate": 1.1669048355008318e-06,
      "loss": 0.0308,
      "step": 16800
    },
    {
      "epoch": 2.8912148249828413,
      "grad_norm": 10.18787670135498,
      "learning_rate": 1.0816047744262097e-06,
      "loss": 0.0285,
      "step": 16850
    },
    {
      "epoch": 2.899794097460535,
      "grad_norm": 1.004296064376831,
      "learning_rate": 9.963047133515872e-07,
      "loss": 0.0295,
      "step": 16900
    },
    {
      "epoch": 2.9083733699382295,
      "grad_norm": 0.8416169881820679,
      "learning_rate": 9.110046522769652e-07,
      "loss": 0.0188,
      "step": 16950
    },
    {
      "epoch": 2.9169526424159233,
      "grad_norm": 0.24503500759601593,
      "learning_rate": 8.25704591202343e-07,
      "loss": 0.0151,
      "step": 17000
    },
    {
      "epoch": 2.925531914893617,
      "grad_norm": 0.498020201921463,
      "learning_rate": 7.404045301277208e-07,
      "loss": 0.0205,
      "step": 17050
    },
    {
      "epoch": 2.934111187371311,
      "grad_norm": 9.898580551147461,
      "learning_rate": 6.551044690530986e-07,
      "loss": 0.0346,
      "step": 17100
    },
    {
      "epoch": 2.942690459849005,
      "grad_norm": 0.19856292009353638,
      "learning_rate": 5.698044079784764e-07,
      "loss": 0.0203,
      "step": 17150
    },
    {
      "epoch": 2.9512697323266988,
      "grad_norm": 0.11982881277799606,
      "learning_rate": 4.845043469038542e-07,
      "loss": 0.027,
      "step": 17200
    },
    {
      "epoch": 2.9598490048043926,
      "grad_norm": 0.03415456414222717,
      "learning_rate": 3.992042858292319e-07,
      "loss": 0.0179,
      "step": 17250
    },
    {
      "epoch": 2.9684282772820865,
      "grad_norm": 2.1689634323120117,
      "learning_rate": 3.1390422475460974e-07,
      "loss": 0.0265,
      "step": 17300
    },
    {
      "epoch": 2.9770075497597803,
      "grad_norm": 0.4574873447418213,
      "learning_rate": 2.286041636799875e-07,
      "loss": 0.0181,
      "step": 17350
    },
    {
      "epoch": 2.985586822237474,
      "grad_norm": 1.3438459634780884,
      "learning_rate": 1.433041026053653e-07,
      "loss": 0.0213,
      "step": 17400
    },
    {
      "epoch": 2.994166094715168,
      "grad_norm": 0.2282046675682068,
      "learning_rate": 5.8004041530743107e-08,
      "loss": 0.0336,
      "step": 17450
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.9897429395120388,
      "eval_f1": 0.9879130064822098,
      "eval_loss": 0.03358028084039688,
      "eval_precision": 0.9858217393887453,
      "eval_recall": 0.9900854062167754,
      "eval_runtime": 18585.8177,
      "eval_samples_per_second": 8.062,
      "eval_steps_per_second": 0.067,
      "step": 17484
    }
  ],
  "logging_steps": 50,
  "max_steps": 17484,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.3895216877970944e+17,
  "train_batch_size": 60,
  "trial_name": null,
  "trial_params": null
}
